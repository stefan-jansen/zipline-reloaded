{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NASDAQ Data Link Integration with CustomData\n",
    "\n",
    "This notebook demonstrates how to fetch professional-grade market data from NASDAQ Data Link (formerly Quandl) and integrate it into Zipline using CustomData.\n",
    "\n",
    "## Why NASDAQ Data Link?\n",
    "\n",
    "- **Professional Quality**: Cleaned, adjusted data from reliable sources\n",
    "- **Comprehensive Coverage**: Stocks, futures, options, forex, and more\n",
    "- **Historical Depth**: Data going back decades\n",
    "- **Corporate Actions**: Automatic adjustments for splits and dividends\n",
    "- **API Reliability**: Enterprise-grade API with SLA guarantees\n",
    "\n",
    "## Prerequisites\n",
    "\n",
    "### 1. Get Your API Key\n",
    "\n",
    "1. Sign up at [NASDAQ Data Link](https://data.nasdaq.com/)\n",
    "2. Navigate to Account Settings ‚Üí API Key\n",
    "3. Copy your API key\n",
    "\n",
    "**Pricing:**\n",
    "- **Free Tier**: Limited access, 50 calls/day\n",
    "- **Premium**: Full access to premium datasets, higher rate limits\n",
    "\n",
    "### 2. Set Up API Key\n",
    "\n",
    "**Option A: Environment Variable (Recommended)**\n",
    "```bash\n",
    "# Add to .env file\n",
    "NASDAQ_DATA_LINK_API_KEY=your_api_key_here\n",
    "```\n",
    "\n",
    "**Option B: Direct in Notebook** (for testing only)\n",
    "```python\n",
    "import os\n",
    "os.environ['NASDAQ_DATA_LINK_API_KEY'] = 'your_api_key_here'\n",
    "```\n",
    "\n",
    "### 3. Install Package"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install nasdaq-data-link if not already installed\n",
    "!pip install nasdaq-data-link -q"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Import Libraries and Configure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import nasdaqdatalink\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "from datetime import datetime, timedelta\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Zipline imports\n",
    "from zipline.pipeline.data import create_custom_db, insert_custom_data, from_db\n",
    "from zipline.pipeline.data import query_custom_data, list_custom_dbs, get_custom_db_info\n",
    "from zipline.pipeline import Pipeline\n",
    "from zipline.pipeline.engine import SimplePipelineEngine\n",
    "from zipline.pipeline.loaders.custom_db_loader import DatabaseCustomDataLoader\n",
    "from zipline.utils.calendar_utils import get_calendar\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set up matplotlib\n",
    "plt.style.use('seaborn-v0_8-darkgrid')\n",
    "%matplotlib inline\n",
    "\n",
    "print(\"‚úì Libraries imported successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Configure API Key\n",
    "\n",
    "Load API key from environment or set it directly:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try to load from .env file\n",
    "load_dotenv()\n",
    "\n",
    "# Get API key from environment\n",
    "api_key = os.getenv('NASDAQ_DATA_LINK_API_KEY')\n",
    "\n",
    "if not api_key:\n",
    "    print(\"‚ö†Ô∏è  API key not found in environment!\")\n",
    "    print(\"\\nPlease set your API key using one of these methods:\\n\")\n",
    "    print(\"Method 1: Environment variable\")\n",
    "    print(\"  export NASDAQ_DATA_LINK_API_KEY='your_key_here'\\n\")\n",
    "    print(\"Method 2: .env file\")\n",
    "    print(\"  Add to .env: NASDAQ_DATA_LINK_API_KEY=your_key_here\\n\")\n",
    "    print(\"Method 3: Set directly in this cell (NOT recommended for production)\")\n",
    "    print(\"  Uncomment the line below and add your key:\\n\")\n",
    "    # api_key = 'YOUR_API_KEY_HERE'  # UNCOMMENT AND REPLACE\n",
    "    raise ValueError(\"API key required to continue\")\n",
    "\n",
    "# Configure NASDAQ Data Link\n",
    "nasdaqdatalink.ApiConfig.api_key = api_key\n",
    "\n",
    "print(\"‚úì API key configured successfully!\")\n",
    "print(f\"  Key preview: {api_key[:8]}...{api_key[-4:]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Define Stock Universe\n",
    "\n",
    "NASDAQ Data Link uses database codes for different data sources:\n",
    "- **WIKI**: Historical stock prices (FREE - but discontinued)\n",
    "- **EOD**: End of Day US Stock Prices (Premium)\n",
    "- **SF1**: Core US Fundamentals Data (Premium)\n",
    "\n",
    "For this example, we'll use **EOD** for premium users or **WIKI** for free tier testing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose your data source\n",
    "# 'WIKI' - Free (historical data, no longer updated)\n",
    "# 'EOD' - Premium (current end-of-day prices)\n",
    "DATA_SOURCE = 'EOD'  # Change to 'WIKI' if you don't have premium access\n",
    "\n",
    "# Define stock universe with NASDAQ Data Link codes\n",
    "stocks = {\n",
    "    'AAPL': {'name': 'Apple Inc.', 'sid': 1},\n",
    "    'MSFT': {'name': 'Microsoft Corporation', 'sid': 2},\n",
    "    'GOOGL': {'name': 'Alphabet Inc.', 'sid': 3},\n",
    "    'AMZN': {'name': 'Amazon.com Inc.', 'sid': 4},\n",
    "    'TSLA': {'name': 'Tesla Inc.', 'sid': 5},\n",
    "    'NVDA': {'name': 'NVIDIA Corporation', 'sid': 6},\n",
    "    'META': {'name': 'Meta Platforms Inc.', 'sid': 7},\n",
    "    'JPM': {'name': 'JPMorgan Chase & Co.', 'sid': 8},\n",
    "    'V': {'name': 'Visa Inc.', 'sid': 9},\n",
    "    'WMT': {'name': 'Walmart Inc.', 'sid': 10},\n",
    "}\n",
    "\n",
    "# Date range\n",
    "start_date = '2022-01-01'\n",
    "end_date = '2023-12-31'\n",
    "\n",
    "# Database directory\n",
    "db_dir = '/data/custom_databases'\n",
    "\n",
    "print(f\"Data Source: {DATA_SOURCE}\")\n",
    "print(f\"Stocks: {len(stocks)}\")\n",
    "print(f\"Date Range: {start_date} to {end_date}\")\n",
    "print(f\"Database Directory: {db_dir}\")\n",
    "\n",
    "# Create reverse mappings\n",
    "ticker_to_sid = {ticker: info['sid'] for ticker, info in stocks.items()}\n",
    "sid_to_ticker = {info['sid']: ticker for ticker, info in stocks.items()}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Test API Connection\n",
    "\n",
    "Let's verify the API is working by fetching a single stock:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Testing API connection...\\n\")\n",
    "\n",
    "try:\n",
    "    # Test with Apple stock\n",
    "    test_ticker = 'AAPL'\n",
    "    test_code = f\"{DATA_SOURCE}/{test_ticker}\"\n",
    "    \n",
    "    print(f\"Fetching: {test_code}\")\n",
    "    \n",
    "    # Fetch just 5 days of data as a test\n",
    "    test_data = nasdaqdatalink.get(\n",
    "        test_code,\n",
    "        start_date='2023-01-01',\n",
    "        end_date='2023-01-10',\n",
    "    )\n",
    "    \n",
    "    print(f\"‚úì API connection successful!\\n\")\n",
    "    print(f\"Sample data for {test_ticker}:\")\n",
    "    print(test_data.head())\n",
    "    print(f\"\\nAvailable columns: {', '.join(test_data.columns)}\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"‚ùå API Error: {e}\\n\")\n",
    "    print(\"Common issues:\")\n",
    "    print(\"1. Invalid API key\")\n",
    "    print(\"2. No access to premium datasets (try DATA_SOURCE='WIKI')\")\n",
    "    print(\"3. Rate limit exceeded\")\n",
    "    print(\"4. Network connection issues\")\n",
    "    raise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5: Fetch Historical Data\n",
    "\n",
    "Download complete historical data for all stocks:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Downloading data from NASDAQ Data Link ({DATA_SOURCE})...\\n\")\n",
    "\n",
    "all_data = []\n",
    "failed_tickers = []\n",
    "\n",
    "for ticker, info in stocks.items():\n",
    "    sid = info['sid']\n",
    "    company_name = info['name']\n",
    "    \n",
    "    print(f\"  [{sid}/{len(stocks)}] Fetching {ticker} ({company_name})...\", end=\" \")\n",
    "    \n",
    "    try:\n",
    "        # Construct NASDAQ Data Link code\n",
    "        nasdaq_code = f\"{DATA_SOURCE}/{ticker}\"\n",
    "        \n",
    "        # Fetch data\n",
    "        df = nasdaqdatalink.get(\n",
    "            nasdaq_code,\n",
    "            start_date=start_date,\n",
    "            end_date=end_date,\n",
    "        )\n",
    "        \n",
    "        if df.empty:\n",
    "            print(\"‚ùå No data available\")\n",
    "            failed_tickers.append(ticker)\n",
    "            continue\n",
    "        \n",
    "        # Standardize column names (different sources use different naming)\n",
    "        # EOD uses: Open, High, Low, Close, Volume, Dividend, Split, Adj_Open, Adj_High, Adj_Low, Adj_Close, Adj_Volume\n",
    "        # WIKI uses: Open, High, Low, Close, Volume, Ex-Dividend, Split Ratio, Adj. Open, Adj. High, Adj. Low, Adj. Close, Adj. Volume\n",
    "        \n",
    "        column_mapping = {\n",
    "            'Adj. Open': 'Adj_Open',\n",
    "            'Adj. High': 'Adj_High',\n",
    "            'Adj. Low': 'Adj_Low',\n",
    "            'Adj. Close': 'Adj_Close',\n",
    "            'Adj. Volume': 'Adj_Volume',\n",
    "        }\n",
    "        df = df.rename(columns=column_mapping)\n",
    "        \n",
    "        # Add metadata\n",
    "        df['sid'] = sid\n",
    "        df['ticker'] = ticker\n",
    "        \n",
    "        all_data.append(df)\n",
    "        print(f\"‚úì {len(df)} days\")\n",
    "        \n",
    "    except nasdaqdatalink.errors.quandl_error.NotFoundError:\n",
    "        print(f\"‚ùå Not found in {DATA_SOURCE}\")\n",
    "        failed_tickers.append(ticker)\n",
    "    except nasdaqdatalink.errors.quandl_error.ForbiddenError:\n",
    "        print(f\"‚ùå Access denied (premium data)\")\n",
    "        failed_tickers.append(ticker)\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Error: {e}\")\n",
    "        failed_tickers.append(ticker)\n",
    "\n",
    "print(f\"\\n‚úì Successfully downloaded {len(all_data)}/{len(stocks)} stocks\")\n",
    "if failed_tickers:\n",
    "    print(f\"  Failed: {', '.join(failed_tickers)}\")\n",
    "print(f\"  Total data points: {sum(len(df) for df in all_data):,}\")\n",
    "\n",
    "if not all_data:\n",
    "    raise ValueError(\"No data was downloaded. Check your API access and data source.\")\n",
    "\n",
    "# Display sample data\n",
    "print(f\"\\nSample data for {all_data[0]['ticker'].iloc[0]}:\")\n",
    "print(all_data[0][['Open', 'High', 'Low', 'Close', 'Volume']].head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 6: Create CustomData Database\n",
    "\n",
    "Set up a database for NASDAQ Data Link market data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Creating CustomData database for NASDAQ market data...\\n\")\n",
    "\n",
    "# Create database with comprehensive columns\n",
    "create_custom_db(\n",
    "    'nasdaq-market-data',\n",
    "    columns={\n",
    "        # Raw OHLCV\n",
    "        'open': float,\n",
    "        'high': float,\n",
    "        'low': float,\n",
    "        'close': float,\n",
    "        'volume': float,\n",
    "        # Adjusted OHLCV (splits/dividends)\n",
    "        'adj_open': float,\n",
    "        'adj_high': float,\n",
    "        'adj_low': float,\n",
    "        'adj_close': float,\n",
    "        'adj_volume': float,\n",
    "    },\n",
    "    bar_size='1d',\n",
    "    db_dir=db_dir,\n",
    ")\n",
    "\n",
    "print(\"‚úì Database 'nasdaq-market-data' created successfully!\")\n",
    "\n",
    "# Display database info\n",
    "db_info = get_custom_db_info('nasdaq-market-data', db_dir=db_dir)\n",
    "print(\"\\nDatabase Information:\")\n",
    "for key, value in db_info.items():\n",
    "    print(f\"  {key}: {value}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 7: Insert Data into Database\n",
    "\n",
    "Convert and insert the NASDAQ data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Inserting NASDAQ data into database...\\n\")\n",
    "\n",
    "for i, df in enumerate(all_data, 1):\n",
    "    sid = df['sid'].iloc[0]\n",
    "    ticker = df['ticker'].iloc[0]\n",
    "    \n",
    "    print(f\"  [{i}/{len(all_data)}] Inserting {ticker} (SID {sid})...\", end=\" \")\n",
    "    \n",
    "    try:\n",
    "        # Create MultiIndex DataFrame (field, sid)\n",
    "        data = pd.DataFrame({\n",
    "            ('open', sid): df['Open'],\n",
    "            ('high', sid): df['High'],\n",
    "            ('low', sid): df['Low'],\n",
    "            ('close', sid): df['Close'],\n",
    "            ('volume', sid): df['Volume'],\n",
    "        })\n",
    "        \n",
    "        # Add adjusted columns if available\n",
    "        if 'Adj_Open' in df.columns:\n",
    "            data[('adj_open', sid)] = df['Adj_Open']\n",
    "            data[('adj_high', sid)] = df['Adj_High']\n",
    "            data[('adj_low', sid)] = df['Adj_Low']\n",
    "            data[('adj_close', sid)] = df['Adj_Close']\n",
    "            data[('adj_volume', sid)] = df['Adj_Volume']\n",
    "        else:\n",
    "            # If no adjusted data, use raw data\n",
    "            data[('adj_open', sid)] = df['Open']\n",
    "            data[('adj_high', sid)] = df['High']\n",
    "            data[('adj_low', sid)] = df['Low']\n",
    "            data[('adj_close', sid)] = df['Close']\n",
    "            data[('adj_volume', sid)] = df['Volume']\n",
    "        \n",
    "        # Set MultiIndex\n",
    "        data.columns = pd.MultiIndex.from_tuples(data.columns, names=['field', 'sid'])\n",
    "        \n",
    "        # Insert into database\n",
    "        insert_custom_data(\n",
    "            'nasdaq-market-data',\n",
    "            data,\n",
    "            mode='update',\n",
    "            db_dir=db_dir,\n",
    "        )\n",
    "        \n",
    "        print(f\"‚úì {len(data)} rows\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Error: {e}\")\n",
    "\n",
    "print(\"\\n‚úì All NASDAQ data inserted successfully!\")\n",
    "\n",
    "# Update database info\n",
    "db_info = get_custom_db_info('nasdaq-market-data', db_dir=db_dir)\n",
    "print(f\"\\nTotal rows in database: {db_info.get('row_count', 'N/A'):,}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 8: Query and Verify Data\n",
    "\n",
    "Verify the data was inserted correctly:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Query data for a specific stock\n",
    "test_ticker = list(ticker_to_sid.keys())[0]\n",
    "test_sid = ticker_to_sid[test_ticker]\n",
    "\n",
    "print(f\"Querying data for {test_ticker} (SID {test_sid})...\\n\")\n",
    "\n",
    "result = query_custom_data(\n",
    "    'nasdaq-market-data',\n",
    "    start_date='2023-01-01',\n",
    "    end_date='2023-01-31',\n",
    "    sids=[test_sid],\n",
    "    columns=['close', 'adj_close', 'volume'],\n",
    "    db_dir=db_dir,\n",
    ")\n",
    "\n",
    "print(f\"Retrieved {len(result)} rows\\n\")\n",
    "print(result.head(10))\n",
    "\n",
    "# Compare raw vs adjusted\n",
    "if 'adj_close' in result.columns:\n",
    "    print(f\"\\nAdjustment Analysis:\")\n",
    "    avg_diff = ((result['close'] - result['adj_close']) / result['close'] * 100).abs().mean()\n",
    "    print(f\"  Average difference between Close and Adj_Close: {avg_diff:.2f}%\")\n",
    "    print(\"  (This accounts for splits, dividends, and other corporate actions)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 9: Build Pipeline with NASDAQ Data\n",
    "\n",
    "Create a comprehensive pipeline:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from zipline.pipeline.factors import CustomFactor, SimpleMovingAverage\n",
    "\n",
    "print(\"Loading NASDAQ data into Pipeline...\\n\")\n",
    "\n",
    "# Load the dataset\n",
    "NASDAQData = from_db('nasdaq-market-data', db_dir=db_dir)\n",
    "\n",
    "print(\"‚úì NASDAQData dataset loaded\")\n",
    "print(f\"  Available columns: {', '.join([c for c in dir(NASDAQData) if not c.startswith('_')])}\")\n",
    "\n",
    "# Custom Factors\n",
    "class AdjustedReturn(CustomFactor):\n",
    "    \"\"\"Calculate return using adjusted close prices\"\"\"\n",
    "    inputs = [NASDAQData.adj_close]\n",
    "    window_length = 2\n",
    "    \n",
    "    def compute(self, today, assets, out, adj_close):\n",
    "        out[:] = (adj_close[-1] - adj_close[-2]) / adj_close[-2]\n",
    "\n",
    "class AdjustedVolatility(CustomFactor):\n",
    "    \"\"\"Calculate volatility using adjusted close\"\"\"\n",
    "    inputs = [NASDAQData.adj_close]\n",
    "    window_length = 20\n",
    "    \n",
    "    def compute(self, today, assets, out, adj_close):\n",
    "        returns = np.diff(adj_close, axis=0) / adj_close[:-1]\n",
    "        out[:] = np.std(returns, axis=0)\n",
    "\n",
    "class TrueRange(CustomFactor):\n",
    "    \"\"\"Calculate True Range (ATR component)\"\"\"\n",
    "    inputs = [NASDAQData.high, NASDAQData.low, NASDAQData.close]\n",
    "    window_length = 2\n",
    "    \n",
    "    def compute(self, today, assets, out, high, low, close):\n",
    "        tr1 = high[-1] - low[-1]\n",
    "        tr2 = np.abs(high[-1] - close[-2])\n",
    "        tr3 = np.abs(low[-1] - close[-2])\n",
    "        out[:] = np.maximum(tr1, np.maximum(tr2, tr3))\n",
    "\n",
    "class RelativeVolume(CustomFactor):\n",
    "    \"\"\"Volume relative to 20-day average\"\"\"\n",
    "    inputs = [NASDAQData.volume]\n",
    "    window_length = 20\n",
    "    \n",
    "    def compute(self, today, assets, out, volume):\n",
    "        avg_volume = np.mean(volume[:-1], axis=0)\n",
    "        out[:] = volume[-1] / avg_volume\n",
    "\n",
    "print(\"\\n‚úì Custom factors defined\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 10: Create Advanced Pipeline\n",
    "\n",
    "Build a pipeline with professional technical indicators:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Building advanced pipeline...\\n\")\n",
    "\n",
    "# Define the pipeline\n",
    "pipeline = Pipeline(\n",
    "    columns={\n",
    "        # Price data (use adjusted for accuracy)\n",
    "        'close': NASDAQData.close.latest,\n",
    "        'adj_close': NASDAQData.adj_close.latest,\n",
    "        'volume': NASDAQData.volume.latest,\n",
    "        'adj_volume': NASDAQData.adj_volume.latest,\n",
    "        \n",
    "        # Moving averages (using adjusted close)\n",
    "        'sma_10': SimpleMovingAverage(inputs=[NASDAQData.adj_close], window_length=10),\n",
    "        'sma_20': SimpleMovingAverage(inputs=[NASDAQData.adj_close], window_length=20),\n",
    "        'sma_50': SimpleMovingAverage(inputs=[NASDAQData.adj_close], window_length=50),\n",
    "        'sma_200': SimpleMovingAverage(inputs=[NASDAQData.adj_close], window_length=200),\n",
    "        \n",
    "        # Returns and volatility\n",
    "        'daily_return': AdjustedReturn(),\n",
    "        'volatility_20d': AdjustedVolatility(),\n",
    "        \n",
    "        # Volume analysis\n",
    "        'relative_volume': RelativeVolume(),\n",
    "        \n",
    "        # Technical indicators\n",
    "        'true_range': TrueRange(),\n",
    "        \n",
    "        # Trading signals\n",
    "        'golden_cross': (\n",
    "            SimpleMovingAverage(inputs=[NASDAQData.adj_close], window_length=50) >\n",
    "            SimpleMovingAverage(inputs=[NASDAQData.adj_close], window_length=200)\n",
    "        ),\n",
    "        'above_sma20': NASDAQData.adj_close.latest > SimpleMovingAverage(inputs=[NASDAQData.adj_close], window_length=20),\n",
    "        'high_volume_spike': RelativeVolume() > 2.0,  # Volume > 2x average\n",
    "    }\n",
    ")\n",
    "\n",
    "print(f\"‚úì Pipeline created with {len(pipeline.columns)} columns\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 11: Run Pipeline\n",
    "\n",
    "Execute the pipeline for analysis:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Setting up Pipeline engine...\\n\")\n",
    "\n",
    "# Get trading calendar\n",
    "trading_calendar = get_calendar('NYSE')\n",
    "\n",
    "# Create loader\n",
    "loader = DatabaseCustomDataLoader(\n",
    "    dataset=NASDAQData,\n",
    "    db_path=f\"{db_dir}/nasdaq-market-data.db\",\n",
    ")\n",
    "\n",
    "def get_loader(column):\n",
    "    if column.dataset == NASDAQData:\n",
    "        return loader\n",
    "    raise ValueError(f\"No loader for {column}\")\n",
    "\n",
    "engine = SimplePipelineEngine(\n",
    "    get_loader=get_loader,\n",
    "    asset_finder=None,\n",
    "    default_domain=None,\n",
    ")\n",
    "\n",
    "print(\"‚úì Engine ready\\n\")\n",
    "\n",
    "# Define analysis period\n",
    "analysis_start = pd.Timestamp('2023-06-01', tz='UTC')\n",
    "analysis_end = pd.Timestamp('2023-06-30', tz='UTC')\n",
    "\n",
    "trading_days = trading_calendar.sessions_in_range(analysis_start, analysis_end)\n",
    "\n",
    "print(f\"Analysis period: {analysis_start.date()} to {analysis_end.date()}\")\n",
    "print(f\"Trading days: {len(trading_days)}\\n\")\n",
    "\n",
    "# Run pipeline\n",
    "print(\"Running pipeline...\")\n",
    "results = engine.run_pipeline(\n",
    "    pipeline,\n",
    "    start_date=analysis_start,\n",
    "    end_date=analysis_end,\n",
    ")\n",
    "\n",
    "print(f\"\\n‚úì Pipeline completed!\")\n",
    "print(f\"  Result shape: {results.shape}\")\n",
    "print(f\"  Columns: {len(results.columns)}\\n\")\n",
    "\n",
    "print(\"Sample results:\")\n",
    "print(results.head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 12: Advanced Analysis\n",
    "\n",
    "Analyze the results with professional metrics:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n=== NASDAQ DATA ANALYSIS ===\\n\")\n",
    "\n",
    "# Analysis by stock\n",
    "for sid, ticker in sorted(sid_to_ticker.items()):\n",
    "    if sid in results.index.get_level_values(1):\n",
    "        stock_data = results.xs(sid, level=1)\n",
    "        \n",
    "        print(f\"{ticker} (SID {sid}):\")\n",
    "        print(f\"  Adj Close: ${stock_data['adj_close'].mean():.2f} avg\")\n",
    "        print(f\"  Daily Return: {stock_data['daily_return'].mean()*100:.3f}% avg\")\n",
    "        print(f\"  Volatility: {stock_data['volatility_20d'].mean():.4f}\")\n",
    "        print(f\"  Relative Volume: {stock_data['relative_volume'].mean():.2f}x avg\")\n",
    "        print(f\"  Golden Cross: {stock_data['golden_cross'].any()}\")\n",
    "        print(f\"  Days above SMA20: {stock_data['above_sma20'].sum()}/{len(stock_data)}\")\n",
    "        print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 13: Visualizations\n",
    "\n",
    "Create professional charts:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select stocks for visualization\n",
    "plot_tickers = list(ticker_to_sid.keys())[:4]\n",
    "\n",
    "# Plot 1: Price with multiple moving averages\n",
    "fig, axes = plt.subplots(2, 2, figsize=(16, 10))\n",
    "fig.suptitle('NASDAQ Data - Price Trends with Moving Averages', fontsize=16, fontweight='bold')\n",
    "\n",
    "for idx, ticker in enumerate(plot_tickers):\n",
    "    if ticker not in ticker_to_sid:\n",
    "        continue\n",
    "        \n",
    "    sid = ticker_to_sid[ticker]\n",
    "    if sid not in results.index.get_level_values(1):\n",
    "        continue\n",
    "    \n",
    "    ax = axes[idx // 2, idx % 2]\n",
    "    stock_data = results.xs(sid, level=1)\n",
    "    \n",
    "    # Plot adjusted close and moving averages\n",
    "    ax.plot(stock_data.index, stock_data['adj_close'], label='Adj Close', linewidth=2)\n",
    "    ax.plot(stock_data.index, stock_data['sma_10'], label='SMA 10', linestyle='--', alpha=0.7)\n",
    "    ax.plot(stock_data.index, stock_data['sma_20'], label='SMA 20', linestyle='--', alpha=0.7)\n",
    "    ax.plot(stock_data.index, stock_data['sma_50'], label='SMA 50', linestyle='--', alpha=0.7)\n",
    "    \n",
    "    # Highlight golden cross if present\n",
    "    if stock_data['golden_cross'].any():\n",
    "        ax.axhline(y=stock_data['sma_200'].iloc[-1], color='gold', linestyle=':', \n",
    "                   linewidth=2, label='SMA 200 (Golden Cross)', alpha=0.6)\n",
    "    \n",
    "    ax.set_title(f'{ticker} - Professional Grade Data', fontweight='bold')\n",
    "    ax.set_xlabel('Date')\n",
    "    ax.set_ylabel('Price ($)')\n",
    "    ax.legend()\n",
    "    ax.grid(True, alpha=0.3)\n",
    "    ax.tick_params(axis='x', rotation=45)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot 2: Volume analysis with spikes\n",
    "fig, axes = plt.subplots(2, 1, figsize=(16, 10))\n",
    "fig.suptitle('Volume Analysis - NASDAQ Data', fontsize=16, fontweight='bold')\n",
    "\n",
    "# Absolute volume\n",
    "ax1 = axes[0]\n",
    "for ticker in plot_tickers:\n",
    "    if ticker in ticker_to_sid:\n",
    "        sid = ticker_to_sid[ticker]\n",
    "        if sid in results.index.get_level_values(1):\n",
    "            stock_data = results.xs(sid, level=1)\n",
    "            ax1.plot(stock_data.index, stock_data['adj_volume'] / 1e6, \n",
    "                    label=ticker, linewidth=2, marker='o', markersize=3)\n",
    "\n",
    "ax1.set_title('Adjusted Trading Volume', fontweight='bold')\n",
    "ax1.set_ylabel('Volume (Millions)')\n",
    "ax1.legend()\n",
    "ax1.grid(True, alpha=0.3)\n",
    "\n",
    "# Relative volume\n",
    "ax2 = axes[1]\n",
    "for ticker in plot_tickers:\n",
    "    if ticker in ticker_to_sid:\n",
    "        sid = ticker_to_sid[ticker]\n",
    "        if sid in results.index.get_level_values(1):\n",
    "            stock_data = results.xs(sid, level=1)\n",
    "            ax2.plot(stock_data.index, stock_data['relative_volume'], \n",
    "                    label=ticker, linewidth=2)\n",
    "\n",
    "ax2.axhline(y=2.0, color='red', linestyle='--', linewidth=2, \n",
    "           label='Spike Threshold (2x)', alpha=0.6)\n",
    "ax2.set_title('Relative Volume (vs 20-day Average)', fontweight='bold')\n",
    "ax2.set_xlabel('Date')\n",
    "ax2.set_ylabel('Relative Volume')\n",
    "ax2.legend()\n",
    "ax2.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 14: Trading Signals\n",
    "\n",
    "Generate professional trading signals:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"PROFESSIONAL TRADING SIGNALS - NASDAQ DATA\")\n",
    "print(\"=\"*70 + \"\\n\")\n",
    "\n",
    "latest_date = results.index.get_level_values(0).max()\n",
    "latest_data = results.xs(latest_date, level=0)\n",
    "\n",
    "print(f\"Signal Date: {latest_date.date()}\\n\")\n",
    "\n",
    "# Golden Cross signals (SMA50 > SMA200)\n",
    "golden_cross_stocks = latest_data[latest_data['golden_cross'] == True]\n",
    "print(\"üèÜ GOLDEN CROSS SIGNALS (SMA50 > SMA200):\")\n",
    "if len(golden_cross_stocks) > 0:\n",
    "    for sid in golden_cross_stocks.index:\n",
    "        if sid in sid_to_ticker:\n",
    "            ticker = sid_to_ticker[sid]\n",
    "            price = golden_cross_stocks.loc[sid, 'adj_close']\n",
    "            ret = golden_cross_stocks.loc[sid, 'daily_return'] * 100\n",
    "            print(f\"  {ticker}: ${price:.2f} (Return: {ret:+.2f}%)\")\n",
    "else:\n",
    "    print(\"  None\")\n",
    "\n",
    "# Strong momentum (above SMA20 + positive return)\n",
    "strong_momentum = latest_data[\n",
    "    (latest_data['above_sma20'] == True) & \n",
    "    (latest_data['daily_return'] > 0)\n",
    "]\n",
    "print(f\"\\nüìà STRONG MOMENTUM ({len(strong_momentum)} stocks):\")\n",
    "for sid in strong_momentum.index:\n",
    "    if sid in sid_to_ticker:\n",
    "        ticker = sid_to_ticker[sid]\n",
    "        ret = strong_momentum.loc[sid, 'daily_return'] * 100\n",
    "        vol = strong_momentum.loc[sid, 'relative_volume']\n",
    "        print(f\"  {ticker}: +{ret:.2f}% (Rel Vol: {vol:.2f}x)\")\n",
    "\n",
    "# Volume spikes\n",
    "volume_spikes = latest_data[latest_data['high_volume_spike'] == True]\n",
    "print(f\"\\nüîä VOLUME SPIKES (>2x average, {len(volume_spikes)} stocks):\")\n",
    "for sid in volume_spikes.index:\n",
    "    if sid in sid_to_ticker:\n",
    "        ticker = sid_to_ticker[sid]\n",
    "        rel_vol = volume_spikes.loc[sid, 'relative_volume']\n",
    "        ret = volume_spikes.loc[sid, 'daily_return'] * 100\n",
    "        print(f\"  {ticker}: {rel_vol:.2f}x volume (Return: {ret:+.2f}%)\")\n",
    "\n",
    "# High volatility warnings\n",
    "high_vol_threshold = latest_data['volatility_20d'].quantile(0.75)\n",
    "high_volatility = latest_data[latest_data['volatility_20d'] > high_vol_threshold]\n",
    "print(f\"\\n‚ö†Ô∏è  HIGH VOLATILITY ALERT ({len(high_volatility)} stocks):\")\n",
    "for sid in high_volatility.index:\n",
    "    if sid in sid_to_ticker:\n",
    "        ticker = sid_to_ticker[sid]\n",
    "        vol = high_volatility.loc[sid, 'volatility_20d']\n",
    "        print(f\"  {ticker}: {vol:.4f}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 15: Data Quality Report\n",
    "\n",
    "Verify data quality (important for professional use):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"DATA QUALITY REPORT\")\n",
    "print(\"=\"*70 + \"\\n\")\n",
    "\n",
    "print(f\"Data Source: NASDAQ Data Link ({DATA_SOURCE})\")\n",
    "print(f\"Date Range: {start_date} to {end_date}\")\n",
    "print(f\"Stocks: {len(sid_to_ticker)}\\n\")\n",
    "\n",
    "# Check for adjustment differences\n",
    "print(\"Adjustment Analysis:\")\n",
    "for sid, ticker in sorted(sid_to_ticker.items()):\n",
    "    if sid in results.index.get_level_values(1):\n",
    "        stock_data = results.xs(sid, level=1)\n",
    "        \n",
    "        # Calculate adjustment factor\n",
    "        adj_factor = (stock_data['close'] / stock_data['adj_close']).mean()\n",
    "        \n",
    "        print(f\"  {ticker}: Adjustment factor = {adj_factor:.4f}\")\n",
    "        \n",
    "        if abs(adj_factor - 1.0) > 0.01:\n",
    "            print(f\"    ‚ö†Ô∏è  Significant adjustments detected (splits/dividends)\")\n",
    "\n",
    "# Data completeness\n",
    "print(\"\\nData Completeness:\")\n",
    "expected_days = len(trading_days)\n",
    "for sid, ticker in sorted(sid_to_ticker.items()):\n",
    "    if sid in results.index.get_level_values(1):\n",
    "        stock_data = results.xs(sid, level=1)\n",
    "        actual_days = len(stock_data)\n",
    "        completeness = (actual_days / expected_days) * 100\n",
    "        \n",
    "        print(f\"  {ticker}: {actual_days}/{expected_days} days ({completeness:.1f}%)\")\n",
    "        \n",
    "        if completeness < 95:\n",
    "            print(f\"    ‚ö†Ô∏è  Missing data detected\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"‚úì Quality check complete!\")\n",
    "print(\"=\"*70)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Production Workflow\n",
    "\n",
    "### Daily Update Script\n",
    "\n",
    "Here's how to set up automated daily updates:\n",
    "\n",
    "```python\n",
    "# update_nasdaq_data.py\n",
    "import os\n",
    "import nasdaqdatalink\n",
    "import pandas as pd\n",
    "from datetime import datetime, timedelta\n",
    "from zipline.pipeline.data import insert_custom_data\n",
    "\n",
    "# Configure API\n",
    "nasdaqdatalink.ApiConfig.api_key = os.getenv('NASDAQ_DATA_LINK_API_KEY')\n",
    "\n",
    "# Your stock universe\n",
    "stocks = {'AAPL': 1, 'MSFT': 2, ...}\n",
    "\n",
    "def update_daily():\n",
    "    \"\"\"Fetch and update yesterday's data\"\"\"\n",
    "    yesterday = (datetime.now() - timedelta(days=1)).strftime('%Y-%m-%d')\n",
    "    \n",
    "    for ticker, sid in stocks.items():\n",
    "        try:\n",
    "            # Fetch data\n",
    "            df = nasdaqdatalink.get(\n",
    "                f'EOD/{ticker}',\n",
    "                start_date=yesterday,\n",
    "                end_date=yesterday,\n",
    "            )\n",
    "            \n",
    "            # Format and insert\n",
    "            # ... (same formatting as above)\n",
    "            \n",
    "            print(f\"Updated {ticker}\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error updating {ticker}: {e}\")\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    update_daily()\n",
    "```\n",
    "\n",
    "### Cron Job Setup\n",
    "\n",
    "Schedule daily updates after market close (4:30 PM ET):\n",
    "\n",
    "```bash\n",
    "# Edit crontab\n",
    "crontab -e\n",
    "\n",
    "# Add this line (runs at 5 PM ET daily)\n",
    "0 17 * * 1-5 cd /path/to/zipline && python update_nasdaq_data.py\n",
    "```\n",
    "\n",
    "### Docker Deployment\n",
    "\n",
    "Add to your `docker-compose.yml`:\n",
    "\n",
    "```yaml\n",
    "services:\n",
    "  zipline-jupyter:\n",
    "    environment:\n",
    "      - NASDAQ_DATA_LINK_API_KEY=${NASDAQ_DATA_LINK_API_KEY}\n",
    "```\n",
    "\n",
    "## Best Practices\n",
    "\n",
    "1. **Always use adjusted prices** for returns and analysis\n",
    "2. **Monitor API rate limits** - NASDAQ has strict limits\n",
    "3. **Cache data** - Don't re-download historical data\n",
    "4. **Validate data quality** - Check for gaps and anomalies\n",
    "5. **Handle corporate actions** - Adjusted data accounts for this\n",
    "6. **Backup databases** - Regular backups of your custom databases\n",
    "7. **Version your universe** - Track which stocks you're analyzing\n",
    "8. **Log everything** - Keep logs of data fetches and errors\n",
    "\n",
    "## Next Steps\n",
    "\n",
    "- Add fundamental data from NASDAQ Data Link SF1 database\n",
    "- Implement custom factors for your strategies\n",
    "- Build backtesting framework\n",
    "- Set up alerting for trading signals\n",
    "- Integrate with broker API for live trading\n",
    "\n",
    "## Resources\n",
    "\n",
    "- [NASDAQ Data Link Documentation](https://docs.data.nasdaq.com/)\n",
    "- [NASDAQ Data Link Python Package](https://github.com/Nasdaq/data-link-python)\n",
    "- [Available Datasets](https://data.nasdaq.com/search)\n",
    "- [CustomData Documentation](../docs/CUSTOM_DATA.md)\n",
    "- [Database Storage Guide](../docs/CUSTOM_DATA_DATABASE.md)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
