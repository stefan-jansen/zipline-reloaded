{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Database Storage for CustomData\n",
    "\n",
    "This notebook demonstrates persistent database storage for custom datasets using SQLite.\n",
    "\n",
    "## What You'll Learn\n",
    "\n",
    "1. Creating custom databases\n",
    "2. Inserting data into databases\n",
    "3. Loading datasets from databases\n",
    "4. Querying data efficiently\n",
    "5. Managing multiple databases"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "\n",
    "from zipline.pipeline.data import (\n",
    "    create_custom_db,\n",
    "    insert_custom_data,\n",
    "    from_db,\n",
    "    query_custom_data,\n",
    "    list_custom_dbs,\n",
    "    get_custom_db_info,\n",
    "    drop_custom_db,\n",
    ")\n",
    "from zipline.pipeline import Pipeline\n",
    "\n",
    "# Use /data directory (mounted volume in Docker)\n",
    "DB_DIR = \"/data/custom_databases\"\n",
    "Path(DB_DIR).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "print(f\"✓ Using database directory: {DB_DIR}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Create a Custom Database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a database for fundamental data\n",
    "try:\n",
    "    db_path = create_custom_db(\n",
    "        'fundamentals-daily',\n",
    "        columns={\n",
    "            'pe_ratio': float,\n",
    "            'market_cap': float,\n",
    "            'revenue_growth': float,\n",
    "            'debt_ratio': float,\n",
    "        },\n",
    "        bar_size='1d',\n",
    "        db_dir=DB_DIR,\n",
    "    )\n",
    "    print(f\"✓ Created database at: {db_path}\")\n",
    "except Exception as e:\n",
    "    print(f\"Database might already exist: {e}\")\n",
    "    print(\"Continuing with existing database...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Generate and Insert Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate sample data\n",
    "dates = pd.bdate_range('2022-01-01', '2023-12-31')\n",
    "sids = list(range(1, 21))  # 20 stocks\n",
    "\n",
    "np.random.seed(42)\n",
    "\n",
    "print(f\"Generating data for {len(dates)} dates and {len(sids)} stocks...\")\n",
    "\n",
    "# Create data in MultiIndex format: (field, sid)\n",
    "for field in ['pe_ratio', 'market_cap', 'revenue_growth', 'debt_ratio']:\n",
    "    if field == 'pe_ratio':\n",
    "        values = np.random.uniform(5, 30, (len(dates), len(sids)))\n",
    "    elif field == 'market_cap':\n",
    "        values = np.random.uniform(1e9, 1e11, (len(dates), len(sids)))\n",
    "    elif field == 'revenue_growth':\n",
    "        values = np.random.uniform(-0.1, 0.3, (len(dates), len(sids)))\n",
    "    else:  # debt_ratio\n",
    "        values = np.random.uniform(0, 2, (len(dates), len(sids)))\n",
    "    \n",
    "    # Create DataFrame with MultiIndex columns\n",
    "    data = pd.DataFrame({\n",
    "        (field, sid): values[:, i]\n",
    "        for i, sid in enumerate(sids)\n",
    "    }, index=dates)\n",
    "    data.columns = pd.MultiIndex.from_tuples(\n",
    "        data.columns, names=['field', 'sid']\n",
    "    )\n",
    "    \n",
    "    # Insert data\n",
    "    insert_custom_data('fundamentals-daily', data, mode='update', db_dir=DB_DIR)\n",
    "    print(f\"  ✓ Inserted {field}\")\n",
    "\n",
    "print(\"\\n✓ Data insertion complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. List and Inspect Databases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List all databases\n",
    "dbs = list_custom_dbs(db_dir=DB_DIR)\n",
    "\n",
    "print(f\"Found {len(dbs)} database(s):\\n\")\n",
    "\n",
    "for db in dbs:\n",
    "    print(f\"Database: {db['code']}\")\n",
    "    print(f\"  Bar size: {db['bar_size']}\")\n",
    "    print(f\"  Columns: {list(db['columns'].keys())}\")\n",
    "    print(f\"  Rows: {db['row_count']:,}\")\n",
    "    print(f\"  Size: {db['size_mb']:.2f} MB\")\n",
    "    print(f\"  Created: {db['created_at']}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Query Data from Database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Query all data\n",
    "all_data = query_custom_data('fundamentals-daily', db_dir=DB_DIR)\n",
    "print(f\"Queried all data: {all_data.shape}\")\n",
    "print(f\"\\nFirst few rows:\")\n",
    "print(all_data.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Query specific date range\n",
    "q1_2023 = query_custom_data(\n",
    "    'fundamentals-daily',\n",
    "    start_date=pd.Timestamp('2023-01-01'),\n",
    "    end_date=pd.Timestamp('2023-03-31'),\n",
    "    db_dir=DB_DIR,\n",
    ")\n",
    "print(f\"\\nQ1 2023 data: {q1_2023.shape}\")\n",
    "print(q1_2023.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Query specific stocks and columns\n",
    "specific_query = query_custom_data(\n",
    "    'fundamentals-daily',\n",
    "    start_date=pd.Timestamp('2023-06-01'),\n",
    "    end_date=pd.Timestamp('2023-06-30'),\n",
    "    sids=[1, 2, 3],\n",
    "    columns=['pe_ratio', 'revenue_growth'],\n",
    "    db_dir=DB_DIR,\n",
    ")\n",
    "print(f\"\\nSpecific query (Jun 2023, stocks 1-3, 2 columns): {specific_query.shape}\")\n",
    "print(specific_query.head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Load Dataset from Database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load dataset from database\n",
    "Fundamentals = from_db('fundamentals-daily', db_dir=DB_DIR)\n",
    "\n",
    "print(f\"Loaded dataset: {Fundamentals}\")\n",
    "print(f\"Dataset name: {Fundamentals.__name__}\")\n",
    "print(f\"Columns: {sorted(Fundamentals._column_names)}\")\n",
    "print(f\"\\nDataset info:\")\n",
    "print(Fundamentals.__doc__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Use Database-Backed Data in Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a pipeline using database-backed data\n",
    "value_pipeline = Pipeline(\n",
    "    columns={\n",
    "        'pe': Fundamentals.pe_ratio.latest,\n",
    "        'cap': Fundamentals.market_cap.latest,\n",
    "        'growth': Fundamentals.revenue_growth.latest,\n",
    "        'debt': Fundamentals.debt_ratio.latest,\n",
    "        \n",
    "        # Value criteria\n",
    "        'undervalued': Fundamentals.pe_ratio.latest < 15,\n",
    "        'growing': Fundamentals.revenue_growth.latest > 0.1,\n",
    "        'stable': Fundamentals.debt_ratio.latest < 1.0,\n",
    "        \n",
    "        # Value score\n",
    "        'value_stock': (\n",
    "            (Fundamentals.pe_ratio.latest < 15) &\n",
    "            (Fundamentals.revenue_growth.latest > 0.1) &\n",
    "            (Fundamentals.debt_ratio.latest < 1.0)\n",
    "        ),\n",
    "    },\n",
    "    screen=Fundamentals.pe_ratio.latest < 20,\n",
    ")\n",
    "\n",
    "print(\"✓ Created pipeline with database-backed data\")\n",
    "print(f\"Columns: {list(value_pipeline.columns.keys())}\")\n",
    "\n",
    "# Get the loader\n",
    "loader = Fundamentals.get_loader()\n",
    "print(f\"\\nLoader: {loader}\")\n",
    "print(f\"Database path: {loader.db_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Visualize Database Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Query recent data for visualization\n",
    "recent_data = query_custom_data(\n",
    "    'fundamentals-daily',\n",
    "    start_date=pd.Timestamp('2023-01-01'),\n",
    "    sids=[1, 2, 3, 4, 5],\n",
    "    db_dir=DB_DIR,\n",
    ")\n",
    "\n",
    "# Pivot for plotting\n",
    "pe_pivot = recent_data.reset_index().pivot(index='date', columns='sid', values='pe_ratio')\n",
    "growth_pivot = recent_data.reset_index().pivot(index='date', columns='sid', values='revenue_growth')\n",
    "\n",
    "# Plot\n",
    "fig, axes = plt.subplots(2, 1, figsize=(15, 10))\n",
    "\n",
    "pe_pivot.plot(ax=axes[0], title='PE Ratios Over Time (2023)')\n",
    "axes[0].set_ylabel('PE Ratio')\n",
    "axes[0].legend(title='Stock ID')\n",
    "\n",
    "(growth_pivot * 100).plot(ax=axes[1], title='Revenue Growth % Over Time (2023)')\n",
    "axes[1].set_ylabel('Growth %')\n",
    "axes[1].axhline(y=0, color='r', linestyle='--', alpha=0.3)\n",
    "axes[1].legend(title='Stock ID')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Database Performance\n",
    "\n",
    "Compare query performance for different approaches:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "# Query all data\n",
    "start = time.time()\n",
    "all_data = query_custom_data('fundamentals-daily', db_dir=DB_DIR)\n",
    "time_all = time.time() - start\n",
    "print(f\"Query all data: {time_all:.4f}s ({all_data.shape[0]:,} rows)\")\n",
    "\n",
    "# Query specific date range\n",
    "start = time.time()\n",
    "date_range = query_custom_data(\n",
    "    'fundamentals-daily',\n",
    "    start_date=pd.Timestamp('2023-01-01'),\n",
    "    end_date=pd.Timestamp('2023-01-31'),\n",
    "    db_dir=DB_DIR,\n",
    ")\n",
    "time_range = time.time() - start\n",
    "print(f\"Query date range: {time_range:.4f}s ({date_range.shape[0]:,} rows)\")\n",
    "\n",
    "# Query specific stocks\n",
    "start = time.time()\n",
    "specific = query_custom_data(\n",
    "    'fundamentals-daily',\n",
    "    sids=[1, 2, 3],\n",
    "    db_dir=DB_DIR,\n",
    ")\n",
    "time_specific = time.time() - start\n",
    "print(f\"Query specific sids: {time_specific:.4f}s ({specific.shape[0]:,} rows)\")\n",
    "\n",
    "print(f\"\\n✓ Filtered queries are {time_all/time_range:.1f}x faster than full queries!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "Database storage provides:\n",
    "\n",
    "- ✅ **Persistent storage** - Data survives across sessions\n",
    "- ✅ **Efficient querying** - Only load what you need\n",
    "- ✅ **Scalability** - Handle large datasets\n",
    "- ✅ **Easy management** - List, inspect, query, delete databases\n",
    "- ✅ **Incremental updates** - Update existing data without reloading\n",
    "\n",
    "## Next Steps\n",
    "\n",
    "- Try the other notebooks for advanced examples\n",
    "- Read the [Database Storage Guide](../docs/CUSTOM_DATA_DATABASE.md)\n",
    "- Experiment with your own data!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
